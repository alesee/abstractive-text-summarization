{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to revert mtime: /Library/Fonts\n",
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load needed packages\n",
    "import pandas as pd\n",
    "import random \n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make directory for data \n",
    "# DATA_PATH = 'data/'\n",
    "# os.makedirs(DATA_PATH, exist_ok=True)\n",
    "# RAW_DATA = f'{DATA_PATH}raw_data/'\n",
    "# os.makedirs(RAW_DATA, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Download Dataset\n",
    "First we download and extract the gigaword dataset (~3M) [here](https://drive.google.com/file/d/0B6N7tANPyVeBNmlSX19Ld2xDU1E/view?usp=sharing)\n",
    "\n",
    "Meantime using the BBC dataset (7M) here: https://www.kaggle.com/pariza/bbc-news-summary/download\n",
    "\n",
    "Data downloaded and stored under `data/BBC News Summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data (CNN)\n",
    "# !curl --header \"Host: doc-0c-3o-docs.googleusercontent.com\" --header \"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36\" --header \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\" --header \"Accept-Language: en-US,en;q=0.9\" --header \"Cookie: AUTH_s4a6oitvorbtivfcjm2pefm907l1ntir=08690680304265769485|1531648800000|pm1jthdhng09cikkb0pkdcqlod4d76p8\" --header \"Connection: keep-alive\" \"https://doc-0c-3o-docs.googleusercontent.com/docs/securesc/d1n9duui70mcvt9ph3953bv4foh1d3fm/pb1h3k6beg14nfv16poorm9mr6bl90e3/1531656000000/03129501499031348422/08690680304265769485/0B6N7tANPyVeBNmlSX19Ld2xDU1E?e=download\" -o \"summary.tar.gz\" -L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract files \n",
    "# !tar -xzf summary.tar.gz -C {RAW_DATA} && mv summary.tar.gz {RAW_DATA}\n",
    "# !gunzip {RAW_DATA}sumdata/train/*.*.txt.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass()\n",
    "class BBCNewsDataReader:\n",
    "    base_folder: str\n",
    "    exclusion: list = field(default_factory=list)\n",
    "    \n",
    "    @property\n",
    "    def news_articles_folder(self):\n",
    "        return self.base_folder + '/News Articles'\n",
    "    \n",
    "    @property\n",
    "    def summaries_folder(self):\n",
    "        return self.base_folder + '/Summaries'\n",
    "    \n",
    "    @property\n",
    "    def categories(self):\n",
    "        exclusion_folders = lambda x: x not in [\".DS_Store\"] + self.exclusion\n",
    "        return filter(exclusion_folders, os.listdir(self.news_articles_folder))\n",
    "    \n",
    "    def to_df(self):\n",
    "        df = pd.DataFrame(columns=['article', 'summary', 'category', 'filename'])\n",
    "        for article_folder, summary_folder in self.__category_folders():\n",
    "            category = article_folder.split('/')[-1]\n",
    "            for filename in os.listdir(article_folder):\n",
    "                article = self.__read_file(f'{article_folder}/{filename}')\n",
    "                summary = self.__read_file(f'{summary_folder}/{filename}')\n",
    "                df = df.append({'article': article, 'summary': summary, 'category': category, 'filename': filename}, ignore_index=True)\n",
    "        return df\n",
    "                \n",
    "            \n",
    "    def __category_folders(self):\n",
    "        return [\n",
    "            (f'{self.news_articles_folder}/{category}', f'{self.summaries_folder}/{category}') for category in self.categories\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    def __read_file(self, filepath):\n",
    "        with open(filepath) as file:\n",
    "            return file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = BBCNewsDataReader(\n",
    "        base_folder='data/BBC News Summary',\n",
    "        exclusion=['entertainment', 'tech', 'sport', 'politics'] # remove these to read all data\n",
    "    ).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK economy facing 'major risks'\\n\\nThe UK manu...</td>\n",
       "      <td>\"Despite some positive news for the export sec...</td>\n",
       "      <td>business</td>\n",
       "      <td>289.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aids and climate top Davos agenda\\n\\nClimate c...</td>\n",
       "      <td>At the same time, about 100,000 people are exp...</td>\n",
       "      <td>business</td>\n",
       "      <td>504.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asian quake hits European shares\\n\\nShares in ...</td>\n",
       "      <td>The unfolding scale of the disaster in south A...</td>\n",
       "      <td>business</td>\n",
       "      <td>262.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India power shares jump on debut\\n\\nShares in ...</td>\n",
       "      <td>Shares in India's largest power producer, Nati...</td>\n",
       "      <td>business</td>\n",
       "      <td>276.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lacroix label bought by US firm\\n\\nLuxury good...</td>\n",
       "      <td>LVMH said the French designer's haute couture ...</td>\n",
       "      <td>business</td>\n",
       "      <td>510.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  UK economy facing 'major risks'\\n\\nThe UK manu...   \n",
       "1  Aids and climate top Davos agenda\\n\\nClimate c...   \n",
       "2  Asian quake hits European shares\\n\\nShares in ...   \n",
       "3  India power shares jump on debut\\n\\nShares in ...   \n",
       "4  Lacroix label bought by US firm\\n\\nLuxury good...   \n",
       "\n",
       "                                             summary  category filename  \n",
       "0  \"Despite some positive news for the export sec...  business  289.txt  \n",
       "1  At the same time, about 100,000 people are exp...  business  504.txt  \n",
       "2  The unfolding scale of the disaster in south A...  business  262.txt  \n",
       "3  Shares in India's largest power producer, Nati...  business  276.txt  \n",
       "4  LVMH said the French designer's haute couture ...  business  510.txt  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Train, Test and Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join validation sentence pairs together into dataframe\n",
    "val = pd.concat([pd.read_csv(f'{RAW_DATA}sumdata/train/valid.article.filter.txt', sep=\"\\n\"), \n",
    "                  pd.read_csv(f'{RAW_DATA}sumdata/train/valid.title.filter.txt', sep=\"\\n\")], axis=1)\n",
    "val.columns = [\"article\", \"title\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join validation sentence pairs together into dataframe\n",
    "# val = pd.concat([pd.read_csv(f'{RAW_DATA}sumdata/train/valid.article.filter.txt', sep=\"\\n\"), \n",
    "#                   pd.read_csv(f'{RAW_DATA}sumdata/train/valid.title.filter.txt', sep=\"\\n\")], axis=1)\n",
    "# val.columns = [\"article\", \"title\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3803956, 189650)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new zealand share prices closed #.## percent higher monday in subdued trading ahead of a us holiday , dealers said .'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'new zealand stocks close #.## percent higher'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"kenyan police have a mounted a ##-hour patrol in a village where us presidential candidate barack obama 's grandmother lives after robbers made a botched attempt to rob her solar panel , an official said .\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"kenyan police offer obama 's grandmother security after robbery\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'an israeli military helicopter with a two-man crew crashed near the northern town of afula and burst into flames on wednesday , army radio said .'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'military helicopter crashes in israel'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"bolivian president evo morales on wednesday declared the us ambassador to la paz `` persona non grata , '' accusing the envoy of encouraging the breakup of the country by promoting separatism .\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'bolivia president orders us envoy expelled'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'the algerian cabinet chaired by president abdelaziz bouteflika on sunday adopted the #### finance bill predicated on an oil price of ## dollars a barrel and a growth rate of #.# percent , it was announced here .'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'algeria adopts #### finance bill with oil put at ## dollars a barrel'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    r = random.randint(0,50)\n",
    "    display(data.iloc[r]['article'])\n",
    "    display(data.iloc[r]['title'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data in tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_PATH = f'{DATA_PATH}processed_data/'\n",
    "os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save train, val datasets \n",
    "data.to_csv(f'{PROCESSED_DATA_PATH}train_ds.csv', index=None)\n",
    "val.to_csv(f'{PROCESSED_DATA_PATH}valid_ds.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DATA_PATH = f'{DATA_PATH}sample_data/'\n",
    "os.makedirs(SAMPLE_DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = data.sample(80000)\n",
    "sample_val = val.sample(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 20000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_train), len(sample_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save sample train, val, and test datasets \n",
    "sample_train.to_csv(f'{SAMPLE_DATA_PATH}train_ds.csv', index=None)\n",
    "sample_val.to_csv(f'{SAMPLE_DATA_PATH}valid_ds.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Smaller Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_ = data.sample(64)\n",
    "sample_val_ = val.sample(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_train_), len(sample_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save sample train, val, and test datasets \n",
    "sample_train_.to_csv(f'{SAMPLE_DATA_PATH}train_ds_.csv', index=None)\n",
    "sample_val_.to_csv(f'{SAMPLE_DATA_PATH}valid_ds_.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DATA_PATH = 'data/'\n",
    "PROCESSED_DATA_PATH = f'{DATA_PATH}processed_data/'\n",
    "data = pd.read_csv(f'{PROCESSED_DATA_PATH}train_ds.csv')\n",
    "val = pd.read_csv(f'{PROCESSED_DATA_PATH}valid_ds.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
